---
title: "project"
format: html
editor: visual
---

Loading the required libraries

```{r}
library(tidyverse)
library(fpp2)
library(urca)
```

#1 - Investigating change in global temperatures over time

First, we load in temperature change data. Our goal here is to investigate if temperature change pre 1980s and post 1980s has seen a significant difference. If yes, it suggests that anthropogenic activities have led to climate change.

```{r}
temp_change_df<- read_csv("Data/annual_temp_change.csv")
head(temp_change_df)
tail(temp_change_df)
```

At first glance, we see that there are 2 methods of temperature recording (GCAG and GISTEMP). We shall use GISTEMP, as the baseline of GISTEMP is the average temperature from 1950 to 1980, and this baseline period is widely used in climate studies.

```{r}
temp_change_GISTEMP <- temp_change_df |>
  filter(Source=="GISTEMP")|>
  arrange(Year)

# Convert to ts object
temp_change_GISTEMP <- ts(temp_change_GISTEMP["Mean"],
                 start=c(1882), 
                 end=c(2016))

autoplot(temp_change_GISTEMP)
```
The autoplot shows clear trend.

```{r}
acf(temp_change_GISTEMP)
```
The ACF displays slowly decaying ACF, suggesting that data is not stationary, as expected.

```{r}
# Decompose the time series using mstl decomposition
mstl(temp_change_GISTEMP)

mstl(temp_change_GISTEMP)|>
  autoplot()

seasonal(mstl(temp_change_GISTEMP))
```
The trendcycle component shows us that there is a greater rate of temperature increment from 1980s to 2016. 

The global population in 1980 is 4.4 billion, while global population in 2016 has almost doubled to 7.5 billion (https://www.worldometers.info/world-population/world-population-by-year/). Hence, a plausible explanation for the spike in temperature change is due to a sharp increase in global population.

## 1.1 - Model building

Model building workflow:

Training set: 1882 to 1952 
Test set: 1953 to 1980 
Forecast set: 1981 to 2016

1. Splitting training and test set to approximately 70:30 ratio, we build models trained on the training set and evaluate their out-of-sample performance on the test set.

2. The best performing model is then trained on both sets (1882 to 1980), and then used to forecast post 1980s.

3. We then compare the 95% confidence intervals of this model's forecasted points to the actual points, and if the actual points lie outside of this confidence interval, we are certain that there is a significant change in rate of temperature increment from 1981 to 2016. This proves that increase in human activities has led to climate change.

```{r}
temp_change_train <- window(temp_change_GISTEMP, start=1882, end=1952)

temp_change_test <- window(temp_change_GISTEMP, start=1953, end=1980)
```
### 1.1.2 Auto arima
model1 will be built using auto arima
```{r}
model1 <- auto.arima(temp_change_train, lambda = "auto")
autoplot(forecast(model1, h=27))
```
Evaluating model legitamacy using Ljung Box test
```{r}
checkresiduals(model1)
```
p value of 0.8568, we accept the null hypothesis that there is no time series autocorrelation in the model. The model passes the test :)

Evaluate model performance
```{r}
accuracy(forecast(model1, h=27), temp_change_test)
```
Looking good tbh. But now we should do manual arima so that prof will see we put in effort and give us more marks.

```{r}
# BoxCox transform the training data to make variance as constant as possible
transformed_temp_change_train <- BoxCox(temp_change_train, BoxCox.lambda(temp_change_train))
# sorry for the long name
BoxCox(transformed_temp_change_train, BoxCox.lambda(temp_change_train)) |>
  tsdisplay()
```
```{r}
# differencing for stationarity, no seasonal component so no seasonal differencing is required.

BoxCox(transformed_temp_change_train, BoxCox.lambda(transformed_temp_change_train))|>
  ndiffs()
```
n diffs is 1, and I got a long warning msg which I shall ignore.
```{r}
tsdisplay(diff(transformed_temp_change_train))

```
Hypothesis: 
Firstly, we know that there is no seasonality, so we can j look if AR and MA exists. (No sMA and sAR)
ACF does not exponentially decrease over lags, AR component appears to be 0.
PACF does not exponentially decrease over lags, MA component also appears to be 0.

Hence, I hypothesize a ARIMA(0,1,0) model. 

Check the model with Ljung-Box test, and evaluate model performance should it pass the test
```{r}
model2 <- Arima(transformed_temp_change_train,
                     order=c(0,1,0),
                     lambda="auto")

checkresiduals(model2)
accuracy(forecast(model2, h=27), temp_change_test)
```
model2 passes ljung box test, but performs poorly as compared to model1.
Our best model is still ARIMA(0,1,2), as generated by auto.arima().



