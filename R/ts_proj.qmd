---
title: "ts_project"
format: html
editor: visual
---

Loading required libraries

```{r}
library(tidyverse)
library(fpp2)
library(urca)
library(TSstudio)
library(tsDyn)
```

# 1.0 Green model (Temperature, Sea levels and CO2 emissions)

## 1.1 Data processing

Loading and cleaning global temperature dataset from Berkley Earth.

```{r}
global_temp_df <- read_csv("C:/Users/rayne/Documents/GitHub/DSA301_TimeSeries/Data/GlobalTemperatures.csv")

# Remove NA values in LandAndOceanAverageTemperature
global_temp_df <- global_temp_df |>
  filter(!is.na(LandAndOceanAverageTemperature))

# Converting from monthly to yearly, then renaming columns for consistency
global_temp_df <- global_temp_df |>
  group_by(year(dt)) |>
  summarize(LandAverageTemperature=mean(LandAverageTemperature))|>
  rename(year=`year(dt)`, global_temperature=LandAverageTemperature)

# range(global_temp_df$year)
```

Loading and cleaning sea levels data

```{r}
sea_levels_df <- read_csv("C:/Users/rayne/Documents/GitHub/DSA301_TimeSeries/Data/Global Mean Sea Levels (1880 to 2013).csv")

# Selecting only relevant columns, then renaming for consistency
sea_levels_df <- sea_levels_df |>
  select(Year, `CSIRO Adjusted Sea Level`)|>
  rename(year=Year, sea_level=`CSIRO Adjusted Sea Level`)
```

Loading and cleaning carbon emissions data

```{r}
emissions_df <- read_csv("C:/Users/rayne/Documents/GitHub/DSA301_TimeSeries/Data/emission data.csv")

# Pivot longer to make years become rows instead of columns in the raw data, then filtering World to get the global emissions, then selecting only the relevant columns, and lastly converting year from character to numeric for left join later on.
emissions_df <- emissions_df |>
  pivot_longer(-Country, names_to="year", values_to="carbon_emissions")|>
  filter(Country=="World", year>1879)|>
  select(-Country)|>
  mutate(year=as.numeric(year))
```


Loading world population data, with data pre-1951s naively filled. In the past, population did not grow as quickly, which justifies the use of a naive method for filling.

Population data is to help normalize CO2 emissions as part of feature engineering, in order to improve green model performance.

```{r}
world_pop <- read_csv("C:/Users/rayne/Documents/GitHub/DSA301_TimeSeries/Data/world_population.csv")

world_pop <- world_pop |>
  filter(Year<2018)|>
  select(year=Year, `World Population`)|>
  arrange((year))
```

Now, we get the emissions per global capita.

```{r}
emissions_df <-emissions_df |>
  mutate(carbon_emissions_per_capita=emissions_df$carbon_emissions/world_pop$`World Population`)|>
  select(year, carbon_emissions_per_capita, carbon_emissions)
```

Merging the 3 cleaned datasets to a green_model_df, which will be used to create models for the the green model.

```{r}
green_model_df <-global_temp_df |>
  left_join(sea_levels_df, by="year")|>
  left_join(emissions_df, by="year")

```

For the complete green_model_df, we start from 1881 to 2013 (sea_level_df is the limiting dataset). Lastly, we have to convert year from numeric to date.

```{r}
green_model_df <-green_model_df |>
 filter(year>1879 & year<2014)|>
  mutate(year=make_date(year))

```

Creating timeseries object with the 3 variables for multivariate modelling, and autoplotting each respective variable for data visualization.

```{r}
# Create TS
green_model_ts <- ts(green_model_df[c("carbon_emissions_per_capita", 
                                      "global_temperature", 
                                      "sea_level")],
                     start=c(1880,1),
                     end=c(2013,1))

green_model_ts |> autoplot()

ts(green_model_df[c("global_temperature")],
                     start=c(1880,1),
                     end=c(2013,1)) |> autoplot()

ts(green_model_df[c("carbon_emissions_per_capita")],
                     start=c(1880,1),
                     end=c(2013,1))|> autoplot()

ts(green_model_df[c("sea_level")],
                     start=c(1880,1),
                     end=c(2013,1))|> autoplot()
```

## 1.2 Model building

### 1.2.1 VAR

Building VAR models

```{r}
vars::VARselect(green_model_ts[,1:3])
```

Check if VAR model passes tests

```{r}
var1 <- vars::VAR(green_model_ts[,1:3], p=1, type="const")
vars::serial.test(var1, lags.pt=10, type="PT.asymptotic")
```

```{r}
var2 <- vars::VAR(green_model_ts[,1:3], p=2, type="const")
vars::serial.test(var2, lags.pt=10, type="PT.asymptotic")
```

```{r}
var3 <- vars::VAR(green_model_ts[,1:3], p=3, type="const")
vars::serial.test(var3, lags.pt=10, type="PT.asymptotic")
```

p value is 0.773, 0.997, and 0.995 respectively. Hence we accept the H0 for all the VAR models and all passes the Portmanteau test.

Now we measure the goodness-of-fit by looking at out-of-sample RMSE and MAPE for the various VAR models.

VAR of order 1

```{r}
outofsample=10
green_model_ts_split <- ts_split(green_model_ts, sample.out=outofsample)
green_var1 <- vars::VAR(green_model_ts_split$train[,1:3], p=1, type="const")
var_fc <- forecast(green_var1, h=outofsample)
accuracy(x=green_model_ts_split$test[,2:2], var_fc$forecast$global_temperature)
```

VAR of order 2

```{r}
green_var2 <- vars::VAR(green_model_ts_split$train[,1:3], p=2, type="const")
var_fc <- forecast(green_var2, h=outofsample)
accuracy(x=green_model_ts_split$test[,2:2], var_fc$forecast$global_temperature)
```

VAR of order 3

```{r}
green_var3 <- vars::VAR(green_model_ts_split$train[,1:3], p=3, type="const")
var_fc <- forecast(green_var3, h=outofsample)
accuracy(x=green_model_ts_split$test[,2:2], var_fc$forecast$global_temperature)
```

VAR(3) has the lowest test RMSE(0.276) and lowest test MAPE(2.59). Thus, VAR(3) is the optimal model based on model performance alone.

However, we can only use VAR(1). Reason: number of parameters scale very quickly with VAR of higher orders. If VAR(1), there will be 12 variables which require 120 records/years. If VAR(3), we have 30 variables which require 300 years of data! (*10 observations per variable as a rule of thumb to prevent model overfitting*)

VAR variables: (1+pk)k, where k is no. of variables and p is no. of lags

### 1.2.2 VECM

First, we determine number of cointegrating relationships

```{r}
summary(ca.jo(green_model_ts_split$train))
```

The smallest number of cointegrating relationships where we fail to reject the null is r=2. Hence, r=2.

Then, we determine the number of VECM lags with the same method as earlier

```{r}
vars::VARselect(green_model_ts_split$train)
```

Based on the BIC(SC) criteria, 1 lag is used

Measuring the accuracy of VECM with lag=1 and cointegration r=2

```{r}
green_vecm <- VECM(green_model_ts_split$train[,1:3],lag=1, r=2, estim="ML")
vecm_fc <- predict(green_vecm, n.ahead = outofsample)
# accuracy for global temperature forecast
accuracy(x=green_model_ts_split$test[,2], vecm_fc[,2])
```

### 1.2.3 ARIMA

ARIMA model acts as the benchmark model, to which more complex VAR and VECM models will be compared to.

```{r}
auto.arima(green_model_ts_split$train[,2], lambda="auto")
checkresiduals(auto.arima(green_model_ts_split$train[,2], lambda="auto"))
```

auto.arima() chooses ARIMA(0,1,1), but we shall explore other ARIMA possibilities by manually creating models using the ACF & PACF plots.

```{r}
ndiffs((green_model_ts_split$train[,2]))
# 1 difference is needed
tsdisplay(diff(green_model_ts_split$train[,2]))
# AR of 0 and MA of 1 and difference of 1. AR is 0 as ACF is not gradually decreasing. MA could be 1,4 due to cutoffs at those respective lags in ACF.
```

```{r}
arima1 <- Arima(green_model_ts_split$train[,2], lambda="auto", order=c(0,1,4))
arima1
arima2 <- Arima(green_model_ts_split$train[,2], lambda="auto", order=c(0,1,1))
arima2
```

```{r}
checkresiduals(arima1)
checkresiduals(arima2)
```

```{r}
accuracy(x=green_model_ts_split$test[,2], forecast(arima2))
accuracy(x=green_model_ts_split$test[,2], forecast(arima1))
```

## 1.2.4 Conclusion

We have built a VAR(1) model and a VECM(1) with 2 cointegration r=2 model. Comparing the models, the VAR model has lower out of sample RMSE and MAPE than the VECM model.

However, ARIMA outperforms both models. I guess the moral of the story is simple is better and we should incorporate this mindset to our everyday lives :)

# 2.0 Blue model
VAR-X with sea,temp and eXogenous CO2
```{r}
outofsample=10
green_model_ts_split <- ts_split(green_model_ts, sample.out=outofsample)
# global_temperature and sea_level in VAR, carbon_emssions_per_capita as eXogenous
green_var1 <- vars::VAR(green_model_ts_split$train[,2:3], p=1, type="const", exogen = green_model_ts_split$train[,1])

# Making exogenous variable a matrix for dumvar argument in predict() fxn
exog_for_forecasting <- matrix(green_model_ts_split$test[,1], ncol = 1)
varx_fc <- predict(green_var1, n.ahead=outofsample, dumvar=exog_for_forecasting)

# Converting the VAR-X forecast back into time series object, for comparison with time series test data, getting the accuracy.
varx_fc <- ts(var_fc$fcst$global_temperature, start=c(2004,1), end=c(2013,1))
accuracy(x=green_model_ts_split$test[,2], varx_fc)
```

# 3.0 Yellow model

