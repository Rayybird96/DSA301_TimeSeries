import requests
import json


def download_page_views(article_title, start_date, end_date):
    base_url = "https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article"
    endpoint = f"/en.wikipedia.org/all-access/all-agents/{article_title}/daily/{start_date}/{end_date}"

    url = base_url + endpoint

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"
    }

    response = requests.get(url, headers=headers)
    data = response.json()

    if 'items' in data:
        page_views = {}
        for item in data['items']:
            date = item['timestamp'][:8]
            views = item['views']
            page_views[date] = views

        return page_views
    else:
        print("Failed to retrieve page views.")
        return None


import pandas as pd

alldata = pd.DataFrame()
for tart in ["Taylor Swift", "Justin Bieber", "Selena Gomez", "Rihanna", "Billie Eilish", "Alicia Keys", "Ed Sheeran"]: #list generated by searching google for "most popular singers".  I have no real idea who these people are
    tdata = list()
    article_title = tart
    start_date = "20200101"  # Format: YYYYMMDD
    end_date = "20231231"    # Format: YYYYMMDD

    page_views_data = download_page_views(article_title, start_date, end_date)
    tdata = pd.DataFrame([page_views_data])
    tdata = tdata.transpose()
    tdata = tdata.rename(columns = {0:tart})
    if len(alldata)==0:
        alldata = tdata
    else:
        alldata = alldata.merge(tdata, how = 'left', left_index = True, right_index = True)

alldata.to_csv('output_timeseries.csv')